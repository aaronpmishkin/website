@def title = "Aaron Mishkin"


~~~
<div class="container">
<img class="profile" src="/assets/images/japan_photo.png"\>
</div>
~~~

@@short
# Detailed About
@@

### Interests
My research interests are primarily in machine learning and continuous optimization. I am particularly interested in designing robust, tuning-free algorithms for stochastic optimization with applications to fitting neural networks. Such algorithms should be fast and practical, while still possessing rigorous convergence guarantees. This balancing act combines theory and practice and makes optimization for machine learning a very fun space in which to work. 

I am also interested in optimization-based methods for scalable Bayesian inference, such as variational inference. Gaussian processes were my first introduction to "real" machine learning and I still find this model class fascinating.

### Education
I received my bachelor’s degree in computer science from UBC in 2018. During my batchelor’s, I worked with [David Poole](https://www.cs.ubc.ca/~poole/) and [Giuseppe Carenini](https://www.cs.ubc.ca/~carenini/) on preference elicitation. We built [Web ValueCharts](http://valuecharts.cs.ubc.ca/register), a visualization system for multi-criteria decision making [[code](https://github.com/ValueChart/WebValueCharts)].

The last six months of my undergraduate degree were spent with [Emtiyaz Khan](https://emtiyaz.github.io/index.html) at the RIKEN Center for Advanced Intelligence Project (AIP), where I worked on low-rank approaches to Gaussian variational inference in Bayesian neural networks [[arXiv](https://arxiv.org/abs/1811.04504)].

I completed my master's at UBC in 2020, where I was fortunate to be supervised by [Mark Schmidt](https://www.cs.ubc.ca/~schmidtm/). My master's research was primarily on first-order optimization under interpolation conditions. I am very proud of the work we did on (mostly) parameter-free stochastic optimization using the Armjio line-search [[arXiv](https://arxiv.org/abs/1905.09997)].

### Service
I review for NeurIPS, [ICML](/assets/etc/icml_certificate.pdf), ICLR, and AISTATS. 
I also review for the Journal of Machine Learning Research when requested. 

